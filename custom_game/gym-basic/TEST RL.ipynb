{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import gym\n",
    "window_width, window_height = 1000, 500\n",
    "rotation_max, acceleration_max = 0.08, 0.5\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self,env_config={}):\n",
    "        # self.observation_space = gym.spaces.Box()\n",
    "        # self.action_space = gym.spaces.Box()\n",
    "        self.x = window_width/2\n",
    "        self.y = window_height/2\n",
    "        self.ang = 0.\n",
    "        self.vel_x = 0.\n",
    "        self.vel_y = 0.\n",
    "\n",
    "    def init_render(self):\n",
    "        import pygame\n",
    "        pygame.init()\n",
    "        self.window = pygame.display.set_mode((window_width, window_height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def reset(self):\n",
    "        # reset the environment to initial state\n",
    "        return observation\n",
    "\n",
    "    def step(self, action=np.zeros((2),dtype=float)):\n",
    "        # action[0]: acceleration | action[1]: rotation\n",
    "        \n",
    "        # ─── APPLY ROTATION ──────────────────────────────────────────────\n",
    "        self.ang = self.ang + rotation_max * action[1]\n",
    "        if self.ang > np.pi:\n",
    "            self.ang = self.ang - 2 * np.pi\n",
    "        if self.ang < -np.pi:\n",
    "            self.ang = self.ang + 2 * np.pi\n",
    "            \n",
    "        # ─── APPLY ACCELERATION ──────────────────────────────────────────\n",
    "        acceleration = action[0]\n",
    "        # backwards acceleration at half thrust\n",
    "        if acceleration < 0:\n",
    "            acceleration = acceleration * 0.5\n",
    "        self.vel_x = self.vel_x + acceleration_max * acceleration * np.cos(self.ang)\n",
    "        self.vel_y = self.vel_y - acceleration_max * acceleration * np.sin(self.ang)\n",
    "        \n",
    "        # move rocket\n",
    "        self.x = self.x + self.vel_x\n",
    "        self.y = self.y + self.vel_y\n",
    "        \n",
    "        # keep rocket on screen (optional)\n",
    "        if self.x > window_width:\n",
    "            self.x = self.x - window_width\n",
    "        elif self.x < 0:\n",
    "            self.x = self.x + window_width\n",
    "        if self.y > window_height:\n",
    "            self.y = self.y - window_height\n",
    "        elif self.y < 0:\n",
    "            self.y = self.y + window_height\n",
    "            \n",
    "        observation, reward, done, info = 0., 0., False, {}\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.window.fill((0,0,0))\n",
    "        pygame.draw.circle(self.window, (0, 200, 200), (int(self.x), int(self.y)), 6)\n",
    "        # draw orientation\n",
    "        p1 = (self.x - 10 * np.cos(self.ang),self.y + 10 * np.sin(self.ang))\n",
    "        p2 = (self.x + 15 * np.cos(self.ang),self.y - 15 * np.sin(self.ang))\n",
    "        pygame.draw.line(self.window,(0,100,100),p1,p2,2)\n",
    "        pygame.display.update()\n",
    "        \n",
    "def pressed_to_action(keytouple):\n",
    "    action_turn = 0.\n",
    "    action_acc = 0.\n",
    "    if keytouple[274] == 1:  # back\n",
    "        action_acc -= 1\n",
    "    if keytouple[273] == 1:  # forward\n",
    "        action_acc += 1\n",
    "    if keytouple[276] == 1:  # left  is -1\n",
    "        action_turn += 1\n",
    "    if keytouple[275] == 1:  # right is +1\n",
    "        action_turn -= 1\n",
    "    # ─── KEY IDS ─────────\n",
    "    # arrow forward   : 273\n",
    "    # arrow backwards : 274\n",
    "    # arrow left      : 276\n",
    "    # arrow right     : 275\n",
    "    return np.array([action_acc, action_turn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5423c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CustomEnv()\n",
    "environment.init_render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af523ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "while run:\n",
    "    # set game speed to 30 fps\n",
    "    environment.clock.tick(30)\n",
    "    # ─── CONTROLS ───────────────────────────────────────────────────────────────────\n",
    "    # end while-loop when window is closed\n",
    "    get_event = pygame.event.get()\n",
    "    for event in get_event:\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "    # get pressed keys, generate action\n",
    "    get_pressed = pygame.key.get_pressed()\n",
    "    action = pressed_to_action(get_pressed)\n",
    "    # calculate one step\n",
    "    environment.step(action)\n",
    "    # render current state\n",
    "    environment.render()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, ray\n",
    "from gym import spaces\n",
    "from ray.rllib.algorithms import ppo\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "disable_env_checking=True\n",
    "algo = ppo.PPO(env=CustomEnv, config={\"env_config\": {},  # config to pass to env class\n",
    "})\n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv, config=config) \n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv0,config={\"num_workers\": 1})\n",
    "\n",
    "mean_ppo = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee03832",
   "metadata": {},
   "source": [
    "https://github.com/danuo/rocket-meister"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cd3b8",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/ultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    result = algo.train()\n",
    "    print(\"episode reward mean:\", _, result['episode_reward_mean'])\n",
    "    mean_ppo.append(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38233d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from rocket_gym import RocketMeister10\n",
    "tune.run(\n",
    "    \"SAC\", # reinforced learning agent\n",
    "    name = \"Training1\",\n",
    "    # to resume training from a checkpoint, set the path accordingly:\n",
    "    # resume = True, # you can resume from checkpoint\n",
    "    # restore = r'.\\ray_results\\Example\\SAC_RocketMeister10_ea992_00000_0_2020-11-11_22-07-33\\checkpoint_3000\\checkpoint-3000',\n",
    "    checkpoint_freq = 100,\n",
    "    checkpoint_at_end = True,\n",
    "    local_dir = r'./ray_results/',\n",
    "    config={\n",
    "        \"env\": RocketMeister10,\n",
    "        \"num_workers\": 30,\n",
    "        \"num_cpus_per_worker\": 0.5,\n",
    "        \"env_config\":{\n",
    "            \"max_steps\": 1000,\n",
    "            \"export_frames\": False,\n",
    "            \"export_states\": False,\n",
    "            # \"reward_mode\": \"continuous\",\n",
    "            # \"env_flipped\": True,\n",
    "            # \"env_flipmode\": True,\n",
    "            }\n",
    "        },\n",
    "    stop = {\n",
    "        \"timesteps_total\": 5_000_000,\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL2)",
   "language": "python",
   "name": "rl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
