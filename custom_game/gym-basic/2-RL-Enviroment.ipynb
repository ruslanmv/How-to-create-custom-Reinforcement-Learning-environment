{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1363d0b8",
   "metadata": {},
   "source": [
    "# 3 - RL Enviroment \n",
    "In this part we are going to build the most essential Enviroment to create a RL  Pipeline.\n",
    "\n",
    "The first framework that we are going to use is the  **RAY**\n",
    "\n",
    "We are going to  pass either a string name or a Python class to specify an environment.  In particular we are going to choose the simplest local enviroment.\n",
    "\n",
    "Custom env classes passed directly to the algorithm must take a single env_config parameter in their constructor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e085e",
   "metadata": {},
   "source": [
    "### Example 1 - Gym + Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32caadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, ray\n",
    "from gym import spaces\n",
    "from ray.rllib.algorithms import ppo\n",
    "\n",
    "class MyEnv(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "       # There are two actions, first will get reward of 1, second reward of -1. \n",
    "        self.action_space = spaces.Discrete(5)      #<gym.Space>\n",
    "        self.observation_space = spaces.Discrete(2) #<gym.Space>\n",
    "    \n",
    "    def reset(self):\n",
    "        state = 0\n",
    "        #return <obs>\n",
    "        return state\n",
    "                           \n",
    "    def step(self, action):\n",
    "\n",
    "        # if we took an action, we were in state 1\n",
    "        state = 1\n",
    "    \n",
    "        if action == 2:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            \n",
    "        # regardless of the action, game is done after a single step\n",
    "        done = True\n",
    "\n",
    "        info = {}\n",
    "        # return <obs>, <reward: float>, <done: bool>, <info: dict>\n",
    "        return state, reward, done, info   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa6d5d",
   "metadata": {},
   "source": [
    "Python 3.8.x\n",
    "ray 1.0\n",
    "tensorflow 2.3.1\n",
    "tensorflow-probability 0.11\n",
    "gym 0.17.3\n",
    "pygame 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa26072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\dtype.py:82: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\n",
      "  bool = np.bool  # pylint: disable=redefined-builtin\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSAC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# reinforced learning agent\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_at_end\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ray_results/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMyEnv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_cpus_per_worker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexport_frames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexport_states\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"reward_mode\": \"continuous\",\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"env_flipped\": True,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"env_flipmode\": True,\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimesteps_total\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5_000_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\tune.py:484\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reuse_actors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    477\u001b[0m     trainable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         run_or_experiment\u001b[38;5;241m.\u001b[39mrun_identifier\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run_or_experiment, Experiment)\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m run_or_experiment\n\u001b[0;32m    481\u001b[0m     )\n\u001b[0;32m    482\u001b[0m     reuse_actors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;66;03m# Only default to True for function trainables that meet certain conditions\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m         \u001b[43mis_function_trainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    486\u001b[0m             \u001b[38;5;66;03m# Changing resources requires restarting actors\u001b[39;00m\n\u001b[0;32m    487\u001b[0m             scheduler\n\u001b[0;32m    488\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheduler, ResourceChangingScheduler)\n\u001b[0;32m    489\u001b[0m         )\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    491\u001b[0m             \u001b[38;5;66;03m# If GPUs are requested we could run into problems with device memory\u001b[39;00m\n\u001b[0;32m    492\u001b[0m             _check_gpus_in_resources(resources_per_trial)\n\u001b[0;32m    493\u001b[0m         )\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    495\u001b[0m             \u001b[38;5;66;03m# If the resource request is overridden, we don't know if GPUs\u001b[39;00m\n\u001b[0;32m    496\u001b[0m             \u001b[38;5;66;03m# will be requested, yet, so default to False\u001b[39;00m\n\u001b[0;32m    497\u001b[0m             _check_default_resources_override(trainable)\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(scheduler, (PopulationBasedTraining, PopulationBasedTrainingReplay))\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_actors\n\u001b[0;32m    504\u001b[0m ):\n\u001b[0;32m    505\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider boosting PBT performance by enabling `reuse_actors` as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwell as implementing `reset_config` for Trainable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\registry.py:64\u001b[0m, in \u001b[0;36mis_function_trainable\u001b[1;34m(trainable)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"Check if a given trainable is a function trainable.\"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trainable, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 64\u001b[0m     trainable \u001b[38;5;241m=\u001b[39m \u001b[43mget_trainable_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trainable, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(trainable, FunctionType)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trainable, partial)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m callable(trainable)\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\registry.py:45\u001b[0m, in \u001b[0;36mget_trainable_cls\u001b[1;34m(trainable_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trainable_cls\u001b[39m(trainable_name):\n\u001b[1;32m---> 45\u001b[0m     \u001b[43mvalidate_trainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _global_registry\u001b[38;5;241m.\u001b[39mget(TRAINABLE_CLASS, trainable_name)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\registry.py:55\u001b[0m, in \u001b[0;36mvalidate_trainable\u001b[1;34m(trainable_name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_trainable(trainable_name):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Make sure everything rllib-related is registered.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _register_all\n\u001b[1;32m---> 55\u001b[0m     \u001b[43m_register_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_trainable(trainable_name):\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown trainable: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trainable_name)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\__init__.py:39\u001b[0m, in \u001b[0;36m_register_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CONTRIBUTED_ALGORITHMS\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, get_trainable_class_and_config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(ALGORITHMS\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m     37\u001b[0m     CONTRIBUTED_ALGORITHMS\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     38\u001b[0m ):\n\u001b[1;32m---> 39\u001b[0m     register_trainable(key, \u001b[43mget_trainable_class_and_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__fake\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sigmoid_fake_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__parameter_tuning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     42\u001b[0m     register_trainable(key, _get_algorithm_class(key))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\registry.py:65\u001b[0m, in \u001b[0;36m_import_bandit_lints\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_import_bandit_lints\u001b[39m():\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BanditLinTS\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BanditLinTS, BanditLinTS\u001b[38;5;241m.\u001b[39mget_default_config()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\bandit\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     BanditLinTS,\n\u001b[0;32m      3\u001b[0m     BanditLinUCB,\n\u001b[0;32m      4\u001b[0m     BanditLinTSConfig,\n\u001b[0;32m      5\u001b[0m     BanditLinUCBConfig,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBanditLinTS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBanditLinUCB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBanditLinTSConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBanditLinUCBConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\bandit\\bandit.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Algorithm\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlgorithmConfig\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit_tf_policy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BanditTFPolicy\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit_torch_policy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BanditTorchPolicy\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Policy\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\bandit\\bandit_tf_policy.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandit_tf_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     DiscreteLinearModelThompsonSampling,\n\u001b[0;32m     10\u001b[0m     DiscreteLinearModelUCB,\n\u001b[0;32m     11\u001b[0m     DiscreteLinearModel,\n\u001b[0;32m     12\u001b[0m     ParametricLinearModelThompsonSampling,\n\u001b[0;32m     13\u001b[0m     ParametricLinearModelUCB,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcatalog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCatalog\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m restore_original_dimensions\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\bandit\\bandit_tf_model.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelV2\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_modelv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFModelV2\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\__init__.py:77\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _ensure_tf_install\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# from tensorflow_probability.google import tfp_google  # DisableOnExport\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bijectors\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debugging\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\__init__.py:23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import,wildcard-import,line-too-long,g-importing-member\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbijectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabsolute_value\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbsoluteValue\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbijectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maffine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Affine\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbijectors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maffine_linear_operator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AffineLinearOperator\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\absolute_value.py:23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbijectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bijector\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_util\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype_util\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\bijector.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_util\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_util\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribution_util\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype_util\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m name_util\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\distribution_util.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_util\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype_util\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_static\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reparameterization\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorshape_util\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\prefer_static.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype_util\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorshape_util\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m nptf\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Try catch required to avoid breaking Probability opensource presubmits.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# TODO(amitpatankar): Remove this once tf-nightly has latest code.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debugging\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype \u001b[38;5;28;01mas\u001b[39;00m dtypes\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\compat.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_shape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dimension_value\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension_value\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m ]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\v2.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\linalg.py:30\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Don't crash if we can't import bazel-generated numpy versions of TF\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# LinearOperators. This allows external developers to run TF tests without\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# installing bazel.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adjoint_registrations \u001b[38;5;28;01mas\u001b[39;00m _adjoint_registrations\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cholesky_registrations \u001b[38;5;28;01mas\u001b[39;00m _cholesky_registrations\n\u001b[0;32m     32\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inverse_registrations \u001b[38;5;28;01mas\u001b[39;00m _inverse_registrations\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\gen\\adjoint_registrations.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy_math \u001b[38;5;28;01mas\u001b[39;00m math_ops\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_operator\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_operator_adjoint\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear_operator_algebra\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\gen\\linear_operator.py:46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtype \u001b[38;5;28;01mas\u001b[39;00m dtypes\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\dtype.py:82\u001b[0m\n\u001b[0;32m     75\u001b[0m as_dtype \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcopy_docstring(\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf.as_dtype\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m type_value: np\u001b[38;5;241m.\u001b[39mdtype(  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         type_value\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m type_value)\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m     80\u001b[0m real_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m dtype: np\u001b[38;5;241m.\u001b[39mreal(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mas_dtype(dtype)))\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mcomplex\u001b[39m \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcopy_docstring(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf.complex\u001b[39m\u001b[38;5;124m'\u001b[39m, _complex)  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m     86\u001b[0m complex128 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcomplex128\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\numpy\\__init__.py:284\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'"
     ]
    }
   ],
   "source": [
    "tune.run(\n",
    "    \"SAC\", # reinforced learning agent\n",
    "    name = \"Training1\",\n",
    "    checkpoint_freq = 100,\n",
    "    checkpoint_at_end = True,\n",
    "    local_dir = r'./ray_results/',\n",
    "    config={\n",
    "        \"env\": MyEnv,\n",
    "        \"num_workers\": 30,\n",
    "        \"num_cpus_per_worker\": 0.5,\n",
    "        \"env_config\":{\n",
    "            \"max_steps\": 1000,\n",
    "            \"export_frames\": False,\n",
    "            \"export_states\": False,\n",
    "            # \"reward_mode\": \"continuous\",\n",
    "            # \"env_flipped\": True,\n",
    "            # \"env_flipmode\": True,\n",
    "            }\n",
    "        },\n",
    "    stop = {\n",
    "        \"timesteps_total\": 5_000_000,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2ae19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36456c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd1d32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 15:12:35,207\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-01-17 15:12:38,913\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='<class '__main__.MyEnv'>', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('<class '__main__.MyEnv'>').build()` instead. This will raise an error in the future!\n",
      "2023-01-17 15:12:38,914\tINFO algorithm_config.py:2503 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2023-01-17 15:12:38,982\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9788)\u001b[0m 2023-01-17 15:12:50,594\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "2023-01-17 15:12:54,381\tINFO trainable.py:172 -- Trainable.setup took 15.402 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-01-17 15:12:54,385\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "#algo = ppo.PPO(env=MyEnv, config={\"env_config\": {},  # config to pass to env class\n",
    "#})\n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv, config=config) \n",
    "\n",
    "algo = ppo.PPO(env=MyEnv,config={\"num_workers\": 4})\n",
    "\n",
    "mean_ppo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae30180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode reward mean: 0 -0.5975\n",
      "episode reward mean: 1 -0.134\n",
      "episode reward mean: 2 0.22\n",
      "episode reward mean: 3 0.6285\n",
      "episode reward mean: 4 0.7415\n",
      "episode reward mean: 5 0.8035\n",
      "episode reward mean: 6 0.883\n",
      "episode reward mean: 7 0.917\n",
      "episode reward mean: 8 0.9455\n",
      "episode reward mean: 9 0.97\n",
      "episode reward mean: 10 0.988\n",
      "episode reward mean: 11 0.9915\n",
      "episode reward mean: 12 0.9985\n",
      "episode reward mean: 13 0.998\n",
      "episode reward mean: 14 0.9985\n",
      "episode reward mean: 15 1.0\n",
      "episode reward mean: 16 1.0\n",
      "episode reward mean: 17 1.0\n",
      "episode reward mean: 18 1.0\n",
      "episode reward mean: 19 0.9995\n",
      "episode reward mean: 20 1.0\n",
      "episode reward mean: 21 1.0\n",
      "episode reward mean: 22 0.9995\n",
      "episode reward mean: 23 1.0\n",
      "episode reward mean: 24 1.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(25):\n",
    "    result = algo.train()\n",
    "    print(\"episode reward mean:\", _, result['episode_reward_mean'])\n",
    "    mean_ppo.append(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1bafb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = [x for x in range(len(mean_ppo))]\n",
    "\n",
    "plt.plot(xs, mean_ppo)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63087033",
   "metadata": {},
   "source": [
    "### How to use the trained algorithm in RL with PP0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1565fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa82a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56c0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMAGANAV/ray_results\\PPO_MyEnv_2023-01-17_15-12-38f9tlo2y0\\checkpoint_000025\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc021f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Fix the windows path\n",
    "#evaluation = trainer.evaluate(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a91c8b",
   "metadata": {},
   "source": [
    "## Computing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31d32737",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36f4d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4784046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1207b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(observations) # The state which you should determine the action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0f9a8",
   "metadata": {},
   "source": [
    "Given any state compute the action which you get the maximum reward in according to the traning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e8014b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = trainer.compute_single_action(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "843a04b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa1bade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    action = trainer.compute_single_action(observations)\n",
    "    observations, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(\"observations, reward, done, info\",observations, reward, done, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "805eca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obs_1': 2, 'obs_2': 2}\n"
     ]
    }
   ],
   "source": [
    "action = trainer.compute_actions({\"obs_1\": observations, \"obs_2\": observations})\n",
    "print(action)\n",
    "# {'obs_1': 0, 'ob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6b5c7",
   "metadata": {},
   "source": [
    "In the following example we are interested to include pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93878ceb",
   "metadata": {},
   "source": [
    "### Example 2 - Gym + Ray + Pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3793d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "from pygame import display\n",
    "from pygame.surfarray import array3d\n",
    "import random\n",
    "\n",
    "BLACK = pygame.Color(0, 0, 0)\n",
    "WHITE = pygame.Color(255, 255, 255)\n",
    "RED = pygame.Color(255, 0, 0)\n",
    "GREEN = pygame.Color(0, 255, 0)\n",
    "BLUE = pygame.Color(0, 0, 255)\n",
    "\n",
    "#Load images\n",
    "worker_image = pygame.image.load(\"point_blue.png\")\n",
    "#To the image we assing a kind of gym object\n",
    "worker_rect = worker_image.get_rect()\n",
    "worker_pos=[25,25]\n",
    "\n",
    "# Moreover we add a position in the screen display\n",
    "worker_rect.center = (worker_pos[0], worker_pos[1])\n",
    "\n",
    "#Target image and position\n",
    "position_coordinates=[(50,50),\n",
    "                      (100,50),\n",
    "                      (150,50)]\n",
    "\n",
    "target_image = pygame.image.load(\"point_red.png\")\n",
    "\n",
    "class MyEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        # There are two actions, first will get reward of 1, second reward of -1. \n",
    "        self.action_space = spaces.Discrete(1)\n",
    "        self.observation_space = spaces.Discrete(2)\n",
    "        \n",
    "        # We inizialize the display\n",
    "        self.frame_size_x = 200\n",
    "        self.frame_size_y = 200\n",
    "        self.game_window = pygame.display.set_mode((self.frame_size_x, self.frame_size_y))   \n",
    "        self.worker_pos=[25,25]\n",
    "        \n",
    "        #Load images\n",
    "        self.worker_image = pygame.image.load(\"point_blue.png\")\n",
    "        #To the image we assing a kind of gym object\n",
    "        self.worker_rect = worker_image.get_rect()\n",
    "        self.worker_pos=[25,25]\n",
    "        # Moreover we add a position in the screen display\n",
    "        self.worker_rect.center = (worker_pos[0], worker_pos[1])\n",
    "        \n",
    "        self.target_image = pygame.image.load(\"point_red.png\")\n",
    "        self.target_rect = target_image.get_rect()\n",
    "        print('Initial position',100,100)\n",
    "        self.target_rect.center = (100, 100)\n",
    "        self.steps = 0\n",
    "\n",
    "    def reward_value(self,worker,target):\n",
    "         #Check for collision between two rects\n",
    "        if worker.colliderect(target):\n",
    "            print(\"worker, target\",worker, target)\n",
    "            reward=1\n",
    "            done=True    \n",
    "        else:\n",
    "            reward=-1\n",
    "            done=False\n",
    "        return reward\n",
    "              \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        self.worker_pos = self.move(action, self.worker_pos)\n",
    "        if action != None:\n",
    "            print(self.worker_pos)\n",
    "            \n",
    "        # We update the state with an image\n",
    "        self.update_game_state()\n",
    "\n",
    "        if action != None:\n",
    "            #print(self.worker_rect,self.target_rect)\n",
    "            reward= self.reward_value(self.worker_rect,self.target_rect)\n",
    " \n",
    "        # regardless of the action, game is done after step becomes true\n",
    "        reward_tmp, done = self.game_over(reward)\n",
    "        info = {}        \n",
    "        img = self.get_image_array_from_game()\n",
    "        state=img\n",
    "        #print('step:', self.steps)\n",
    "        self.steps += 1\n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def worker_step(self,event):   \n",
    "        '''\n",
    "        Takes human keyboard event and then returns it as an action string\n",
    "        '''\n",
    "        action = None\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "            \n",
    "        #Move based on mouse clicks\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "            self.worker_pos[0]=mouse_x\n",
    "            self.worker_pos[1]=mouse_y\n",
    "            action = 'CLICK'\n",
    "        \n",
    "        #Drag the object when the mouse button is clicked\n",
    "        if event.type == pygame.MOUSEMOTION and event.buttons[0] == 1:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "\n",
    "            self.worker_pos[0]=mouse_x\n",
    "            self.worker_pos[1]=mouse_y\n",
    "            action = 'CLICK'            \n",
    "        \n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "        \n",
    "            # Esc -> Create event to quit the game\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                pygame.event.post(pygame.event.Event(pygame.QUIT))                \n",
    "        return action    \n",
    "    \n",
    "    def update_game_state(self):\n",
    "        \n",
    "        #We fill the screen to white\n",
    "        self.game_window.fill(WHITE)\n",
    "        \n",
    "        #print(self.worker_pos[0],self.worker_pos[1])\n",
    "        self.worker_rect.x=self.worker_pos[0]\n",
    "        self.worker_rect.y=self.worker_pos[1]\n",
    "        \n",
    "        #Draw rectangles to represent the rect's of each object\n",
    "        pygame.draw.rect(self.game_window, (0, 255, 0), self.target_rect, 1)\n",
    "        pygame.draw.rect(self.game_window, (255, 255, 0), self.worker_rect, 1)\n",
    "        \n",
    "        #Blit assets\n",
    "        self.game_window.blit(target_image, self.target_rect)\n",
    "        self.game_window.blit(worker_image, self.worker_rect)\n",
    "        \n",
    "        \n",
    "    def get_image_array_from_game(self):\n",
    "        img = array3d(display.get_surface())\n",
    "        #Preprocessing of channels ( needed for tensorflow)\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "        return img    \n",
    "    \n",
    "    def reset(self):\n",
    "        target_pos=random.choice(position_coordinates)\n",
    "        print('Target position',target_pos[0], target_pos[1])\n",
    "        self.target_rect.center = (target_pos[0], target_pos[1])\n",
    "        self.steps = 0\n",
    "        state = 0\n",
    "        return state\n",
    "    \n",
    "    def move(self,action,worker_pos):\n",
    "        '''\n",
    "        Changes direction based on action input.\n",
    "        Updates Office_pos list to reflect direction change.\n",
    "        '''\n",
    "        if not action:\n",
    "            return worker_pos\n",
    "        if action=='CLICK':\n",
    "            return worker_pos\n",
    "       \n",
    "        return worker_pos    \n",
    "  \n",
    "    def render(self, mode='human'):\n",
    "        if mode == \"human\":\n",
    "            display.update()        \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def game_over(self, reward):\n",
    "        if (reward < 1) or (self.steps >= 100): \n",
    "            return -1, True\n",
    "        else:\n",
    "            return reward, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb037bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position 100 100\n",
      "Target position 50 50\n",
      "action_n 0\n",
      "CLICK\n",
      "[25, 25]\n",
      "worker, target <rect(25, 25, 18, 18)> <rect(41, 41, 18, 18)>\n",
      "Reward = 1 with action = CLICK\n",
      "1 False {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc56b025e0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# method 1 - use local test class\n",
    "env = MyEnv()\n",
    "env.reset()\n",
    "action_n = env.action_space.sample()\n",
    "print('action_n',action_n)\n",
    "action_key={0:'CLICK'}\n",
    "action=action_key[action_n]\n",
    "print(action)\n",
    "state, reward, done, info = env.step(action)\n",
    "print(\"Reward = {} with action = {}\".format(reward,action))\n",
    "import matplotlib.pyplot as plt\n",
    "print(reward, done, info)\n",
    "plt.figure()\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b82ee4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position 100 100\n",
      "[90, 41]\n",
      "Reward = -1 with action = CLICK \n",
      "[90, 41]\n",
      "Reward = -1 with action = CLICK \n",
      "[97, 101]\n",
      "worker, target <rect(97, 101, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[97, 101]\n",
      "worker, target <rect(97, 101, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[97, 97]\n",
      "worker, target <rect(97, 97, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[97, 97]\n",
      "worker, target <rect(97, 97, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[88, 98]\n",
      "worker, target <rect(88, 98, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[88, 98]\n",
      "worker, target <rect(88, 98, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[101, 94]\n",
      "worker, target <rect(101, 94, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[101, 94]\n",
      "worker, target <rect(101, 94, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[101, 94]\n",
      "worker, target <rect(101, 94, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[89, 103]\n",
      "worker, target <rect(89, 103, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n",
      "[89, 103]\n",
      "worker, target <rect(89, 103, 18, 18)> <rect(91, 91, 18, 18)>\n",
      "Reward = 1 with action = CLICK \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "env = MyEnv()\n",
    "# This is technically a FPS Refresh rate\n",
    "FPS = 10\n",
    "# FPS (frames per second) controller\n",
    "fps_controller = pygame.time.Clock()\n",
    "# Checks for errors encountered\n",
    "check_errors = pygame.init()\n",
    "# Initialise game window\n",
    "pygame.display.set_caption('Testing Game') \n",
    "#The main game loop\n",
    "running = True\n",
    "while running:\n",
    "    # Check Input from Human Step \n",
    "    for event in pygame.event.get():\n",
    "        action = env.worker_step(event)    \n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if action != None:\n",
    "        print(\"Reward = {} with action = {} \".format(reward,action))    \n",
    "    # Refresh game screen\n",
    "    pygame.display.update()\n",
    "    # Refresh rate\n",
    "    fps_controller.tick(FPS)\n",
    "    img = array3d(env.game_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31c106c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 15:32:24,225\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-01-18 15:32:28,230\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='<class '__main__.MyEnv0'>', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('<class '__main__.MyEnv0'>').build()` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not serialize the argument <function Algorithm._get_env_id_and_creator.<locals>.<lambda> at 0x000001CC56A62EE0> for a task or actor ray.rllib.evaluation.rollout_worker.RolloutWorker.__init__. Check https://docs.ray.io/en/master/ray-core/objects/serialization.html#troubleshooting for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:441\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_internal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\serialization.py:450\u001b[0m, in \u001b[0;36mSerializationContext.serialize\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize_to_msgpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\serialization.py:428\u001b[0m, in \u001b[0;36mSerializationContext._serialize_to_msgpack\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    427\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m ray_constants\u001b[38;5;241m.\u001b[39mOBJECT_METADATA_TYPE_PYTHON\n\u001b[1;32m--> 428\u001b[0m     pickle5_serialized_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialize_to_pickle5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpython_objects\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\serialization.py:390\u001b[0m, in \u001b[0;36mSerializationContext._serialize_to_pickle5\u001b[1;34m(self, metadata, value)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_and_clear_contained_object_refs()\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\serialization.py:385\u001b[0m, in \u001b[0;36mSerializationContext._serialize_to_pickle5\u001b[1;34m(self, metadata, value)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_in_band_serialization()\n\u001b[1;32m--> 385\u001b[0m     inband \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_callback\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\cloudpickle\\cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[0;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\cloudpickle\\cloudpickle_fast.py:627\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'pygame.Surface' object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m disable_env_checking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#algo = ppo.PPO(env=MyEnv, config={\"env_config\": {},  # config to pass to env class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#})\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#algo = ppo.PPO(env=MyEnv, config=config) \u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyEnv0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m mean_ppo \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:441\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[1;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m     }\n\u001b[0;32m    439\u001b[0m }\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[1;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_node_ip_address()\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:566\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;66;03m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m#   in each training iteration.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;66;03m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;66;03m# has been deprecated.\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:169\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[1;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _setup:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# constructor).\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;66;03m# errors.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:239\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[1;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds_shards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_workers_after_construction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    248\u001b[0m     local_worker\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39mnum_actors() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcreate_env_on_local_worker\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[0;32m    252\u001b[0m ):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:590\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[1;34m(self, num_workers, validate)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"Creates and adds a number of remote workers to this worker set.\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03mCan be called several times on the same WorkerSet to add more\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03m    properly.\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    589\u001b[0m old_num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39mnum_actors()\n\u001b[1;32m--> 590\u001b[0m new_workers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_worker(\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cls,\n\u001b[0;32m    593\u001b[0m         env_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env_creator,\n\u001b[0;32m    594\u001b[0m         validate_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         worker_index\u001b[38;5;241m=\u001b[39mold_num_workers \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    596\u001b[0m         num_workers\u001b[38;5;241m=\u001b[39mold_num_workers \u001b[38;5;241m+\u001b[39m num_workers,\n\u001b[0;32m    597\u001b[0m         config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_config,\n\u001b[0;32m    598\u001b[0m     )\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_workers)\n\u001b[0;32m    600\u001b[0m ]\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39madd_actors(new_workers)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# Validate here, whether all remote workers have been constructed properly\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# and are \"up and running\". Establish initial states.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:591\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"Creates and adds a number of remote workers to this worker set.\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03mCan be called several times on the same WorkerSet to add more\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03m    properly.\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    589\u001b[0m old_num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39mnum_actors()\n\u001b[0;32m    590\u001b[0m new_workers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_num_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_num_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_workers)\n\u001b[0;32m    600\u001b[0m ]\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__worker_manager\u001b[38;5;241m.\u001b[39madd_actors(new_workers)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# Validate here, whether all remote workers have been constructed properly\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# and are \"up and running\". Establish initial states.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:941\u001b[0m, in \u001b[0;36mWorkerSet._make_worker\u001b[1;34m(self, cls, env_creator, validate_env, worker_index, num_workers, recreated_worker, config, spaces)\u001b[0m\n\u001b[0;32m    938\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating TF session \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_session_args\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf1\u001b[38;5;241m.\u001b[39mSession(config\u001b[38;5;241m=\u001b[39mtf1\u001b[38;5;241m.\u001b[39mConfigProto(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_session_args\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m--> 941\u001b[0m worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_session_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession_creator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf_session_args\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecreated_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecreated_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ds_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m worker\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\actor.py:529\u001b[0m, in \u001b[0;36mActorClass.remote\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremote\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Create an actor.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m        A handle to the newly created actor.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py:387\u001b[0m, in \u001b[0;36m_tracing_actor_creation.<locals>._invocation_actor_class_remote_span\u001b[1;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_tracing_enabled():\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ray_metadata__\u001b[38;5;241m.\u001b[39mclass_name\n\u001b[0;32m    390\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\actor.py:968\u001b[0m, in \u001b[0;36mActorClass._remote\u001b[1;34m(self, args, kwargs, **actor_options)\u001b[0m\n\u001b[0;32m    958\u001b[0m         func_name \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mactor_creation_function_descriptor\u001b[38;5;241m.\u001b[39mfunction_name\n\u001b[0;32m    959\u001b[0m     meta\u001b[38;5;241m.\u001b[39mactor_creation_function_descriptor \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    960\u001b[0m         cross_language\u001b[38;5;241m.\u001b[39m_get_function_descriptor_for_actor_method(\n\u001b[0;32m    961\u001b[0m             meta\u001b[38;5;241m.\u001b[39mlanguage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    965\u001b[0m         )\n\u001b[0;32m    966\u001b[0m     )\n\u001b[1;32m--> 968\u001b[0m actor_id \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_creation_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreation_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_task_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactor_placement_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetached\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_asyncio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Store actor_method_cpu in actor handle's extension data.\u001b[39;49;00m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextension_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactor_method_cpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcurrency_groups_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrency_groups_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_pending_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_pending_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _actor_launch_hook:\n\u001b[0;32m    990\u001b[0m     _actor_launch_hook(\n\u001b[0;32m    991\u001b[0m         meta\u001b[38;5;241m.\u001b[39mactor_creation_function_descriptor, resources, scheduling_strategy\n\u001b[0;32m    992\u001b[0m     )\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:1964\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.create_actor\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:1969\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.create_actor\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:407\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:398\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:449\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_internal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not serialize the argument <function Algorithm._get_env_id_and_creator.<locals>.<lambda> at 0x000001CC56A62EE0> for a task or actor ray.rllib.evaluation.rollout_worker.RolloutWorker.__init__. Check https://docs.ray.io/en/master/ray-core/objects/serialization.html#troubleshooting for more information."
     ]
    }
   ],
   "source": [
    "import gym, ray\n",
    "from gym import spaces\n",
    "from ray.rllib.algorithms import ppo\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "disable_env_checking=True\n",
    "#algo = ppo.PPO(env=MyEnv, config={\"env_config\": {},  # config to pass to env class\n",
    "#})\n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv, config=config) \n",
    "\n",
    "algo = ppo.PPO(env=MyEnv0,config={\"num_workers\": 1})\n",
    "\n",
    "mean_ppo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7e836a",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd891775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import gym\n",
    "window_width, window_height = 1000, 500\n",
    "rotation_max, acceleration_max = 0.08, 0.5\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self,env_config={}):\n",
    "        # self.observation_space = gym.spaces.Box()\n",
    "        # self.action_space = gym.spaces.Box()\n",
    "        self.x = window_width/2\n",
    "        self.y = window_height/2\n",
    "        self.ang = 0.\n",
    "        self.vel_x = 0.\n",
    "        self.vel_y = 0.\n",
    "\n",
    "    def init_render(self):\n",
    "        import pygame\n",
    "        pygame.init()\n",
    "        self.window = pygame.display.set_mode((window_width, window_height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def reset(self):\n",
    "        # reset the environment to initial state\n",
    "        return observation\n",
    "\n",
    "    def step(self, action=np.zeros((2),dtype=float)):\n",
    "        # action[0]: acceleration | action[1]: rotation\n",
    "        \n",
    "        # ─── APPLY ROTATION ──────────────────────────────────────────────\n",
    "        self.ang = self.ang + rotation_max * action[1]\n",
    "        if self.ang > np.pi:\n",
    "            self.ang = self.ang - 2 * np.pi\n",
    "        if self.ang < -np.pi:\n",
    "            self.ang = self.ang + 2 * np.pi\n",
    "            \n",
    "        # ─── APPLY ACCELERATION ──────────────────────────────────────────\n",
    "        acceleration = action[0]\n",
    "        # backwards acceleration at half thrust\n",
    "        if acceleration < 0:\n",
    "            acceleration = acceleration * 0.5\n",
    "        self.vel_x = self.vel_x + acceleration_max * acceleration * np.cos(self.ang)\n",
    "        self.vel_y = self.vel_y - acceleration_max * acceleration * np.sin(self.ang)\n",
    "        \n",
    "        # move rocket\n",
    "        self.x = self.x + self.vel_x\n",
    "        self.y = self.y + self.vel_y\n",
    "        \n",
    "        # keep rocket on screen (optional)\n",
    "        if self.x > window_width:\n",
    "            self.x = self.x - window_width\n",
    "        elif self.x < 0:\n",
    "            self.x = self.x + window_width\n",
    "        if self.y > window_height:\n",
    "            self.y = self.y - window_height\n",
    "        elif self.y < 0:\n",
    "            self.y = self.y + window_height\n",
    "            \n",
    "        observation, reward, done, info = 0., 0., False, {}\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.window.fill((0,0,0))\n",
    "        pygame.draw.circle(self.window, (0, 200, 200), (int(self.x), int(self.y)), 6)\n",
    "        # draw orientation\n",
    "        p1 = (self.x - 10 * np.cos(self.ang),self.y + 10 * np.sin(self.ang))\n",
    "        p2 = (self.x + 15 * np.cos(self.ang),self.y - 15 * np.sin(self.ang))\n",
    "        pygame.draw.line(self.window,(0,100,100),p1,p2,2)\n",
    "        pygame.display.update()\n",
    "        \n",
    "def pressed_to_action(keytouple):\n",
    "    action_turn = 0.\n",
    "    action_acc = 0.\n",
    "    if keytouple[274] == 1:  # back\n",
    "        action_acc -= 1\n",
    "    if keytouple[273] == 1:  # forward\n",
    "        action_acc += 1\n",
    "    if keytouple[276] == 1:  # left  is -1\n",
    "        action_turn += 1\n",
    "    if keytouple[275] == 1:  # right is +1\n",
    "        action_turn -= 1\n",
    "    # ─── KEY IDS ─────────\n",
    "    # arrow forward   : 273\n",
    "    # arrow backwards : 274\n",
    "    # arrow left      : 276\n",
    "    # arrow right     : 275\n",
    "    return np.array([action_acc, action_turn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "191f0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CustomEnv()\n",
    "environment.init_render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc0a90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "while run:\n",
    "    # set game speed to 30 fps\n",
    "    environment.clock.tick(30)\n",
    "    # ─── CONTROLS ───────────────────────────────────────────────────────────────────\n",
    "    # end while-loop when window is closed\n",
    "    get_event = pygame.event.get()\n",
    "    for event in get_event:\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "    # get pressed keys, generate action\n",
    "    get_pressed = pygame.key.get_pressed()\n",
    "    action = pressed_to_action(get_pressed)\n",
    "    # calculate one step\n",
    "    environment.step(action)\n",
    "    # render current state\n",
    "    environment.render()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c798fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 15:01:32,713\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-01-18 15:01:36,167\tWARNING deprecation.py:47 -- DeprecationWarning: `algo = Algorithm(env='<class '__main__.CustomEnv'>', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('<class '__main__.CustomEnv'>').build()` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m 2023-01-18 15:01:43,082\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     raise ValueError(\"Observation space must be a gym.space\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m ValueError: Observation space must be a gym.space\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 592, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     check_env(self.env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 88, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     check_gym_environments(env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m     raise ValueError(\"Observation space must be a gym.space\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m ValueError: Observation space must be a gym.space\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m 2023-01-18 15:01:43,095\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=27316, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000024AC80CED60>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     raise ValueError(\"Observation space must be a gym.space\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m ValueError: Observation space must be a gym.space\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=27316, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000024AC80CED60>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 592, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     check_env(self.env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 88, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     raise ValueError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m ValueError: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     check_gym_environments(env)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m   File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m     raise ValueError(\"Observation space must be a gym.space\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m ValueError: Observation space must be a gym.space\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n",
      "2023-01-18 15:01:43,103\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "    raise ValueError(\"Observation space must be a gym.space\")\n",
      "ValueError: Observation space must be a gym.space\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 592, in __init__\n",
      "    check_env(self.env)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 88, in check_env\n",
      "    raise ValueError(\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n",
      "    check_gym_environments(env)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "    raise ValueError(\"Observation space must be a gym.space\")\n",
      "ValueError: Observation space must be a gym.space\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 15:01:43,104\tERROR actor_manager.py:486 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=27316, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000024AC80CED60>)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "    raise ValueError(\"Observation space must be a gym.space\")\n",
      "ValueError: Observation space must be a gym.space\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=27316, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000024AC80CED60>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 592, in __init__\n",
      "    check_env(self.env)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 88, in check_env\n",
      "    raise ValueError(\n",
      "ValueError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n",
      "    check_gym_environments(env)\n",
      "  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n",
      "    raise ValueError(\"Observation space must be a gym.space\")\n",
      "ValueError: Observation space must be a gym.space\n",
      "\n",
      "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m pygame 2.1.2 (SDL 2.0.18, Python 3.8.0)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27316)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m pygame 2.1.2 (SDL 2.0.18, Python 3.8.0)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=16144)\u001b[0m Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n    check_gym_environments(env)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n    raise ValueError(\"Observation space must be a gym.space\")\nValueError: Observation space must be a gym.space\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:169\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[1;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# constructor).\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:239\u001b[0m, in \u001b[0;36mWorkerSet._setup\u001b[1;34m(self, validate_env, config, num_workers, local_worker)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_workers_after_construction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:612\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[1;34m(self, num_workers, validate)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:473\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[1;34m(self, remote_actor_ids, remote_calls, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m     remote_results\u001b[38;5;241m.\u001b[39madd_result(actor_id, ResultOrError(result\u001b[38;5;241m=\u001b[39mresult))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\worker.py:2311\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2311\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m   2313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_individual_id:\n",
      "\u001b[1;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n    raise ValueError(\"Observation space must be a gym.space\")\nValueError: Observation space must be a gym.space\n\nDuring handling of the above exception, another exception occurred:\n\n\u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=16144, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000181F599EDC0>)\n  File \"python\\ray\\_raylet.pyx\", line 823, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 875, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 830, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 834, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 674, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 466, in _resume_span\n    return method(self, *_args, **_kwargs)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py\", line 592, in __init__\n    check_env(self.env)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 88, in check_env\n    raise ValueError(\nValueError: Traceback (most recent call last):\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n    check_gym_environments(env)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n    raise ValueError(\"Observation space must be a gym.space\")\nValueError: Observation space must be a gym.space\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m ray\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m      6\u001b[0m disable_env_checking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m algo \u001b[38;5;241m=\u001b[39m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCustomEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# config to pass to env class\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#algo = ppo.PPO(env=MyEnv, config=config) \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#algo = ppo.PPO(env=MyEnv0,config={\"num_workers\": 1})\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mean_ppo \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:441\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[1;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m     }\n\u001b[0;32m    439\u001b[0m }\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:169\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[1;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mget_node_ip_address()\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:566\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Only if user did not override `_init()`:\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;66;03m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m#   in each training iteration.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;66;03m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;66;03m# has been deprecated.\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_policy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# TODO (avnishn): Remove the execution plan API by q1 2023\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;66;03m# Function defining one single training iteration's behavior.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_disable_execution_plan_api\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;66;03m# Ensure remote workers are initially in sync with the local worker.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py:191\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[1;34m(self, env_creator, validate_env, default_policy_class, config, num_workers, local_worker, logdir, _setup, policy_class, trainer_config)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# errors.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mactor_init_failed:\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;66;03m# Raise the original error here that the RolloutWorker raised\u001b[39;00m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;66;03m# during its construction process. This is to enforce transparency\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# - e.args[0].args[2]: The original Exception (e.g. a ValueError due\u001b[39;00m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# to a config mismatch) thrown inside the actor.\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# In any other case, raise the RayActorError as-is.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 77, in check_env\n    check_gym_environments(env)\n  File \"C:\\Users\\RMAGANAV\\Anaconda3\\envs\\rl2\\lib\\site-packages\\ray\\rllib\\utils\\pre_checks\\env.py\", line 140, in check_gym_environments\n    raise ValueError(\"Observation space must be a gym.space\")\nValueError: Observation space must be a gym.space\n\nThe above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior by setting `disable_env_checking=True` in your environment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([env])."
     ]
    }
   ],
   "source": [
    "import gym, ray\n",
    "from gym import spaces\n",
    "from ray.rllib.algorithms import ppo\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "disable_env_checking=True\n",
    "algo = ppo.PPO(env=CustomEnv, config={\"env_config\": {},  # config to pass to env class\n",
    "})\n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv, config=config) \n",
    "\n",
    "#algo = ppo.PPO(env=MyEnv0,config={\"num_workers\": 1})\n",
    "\n",
    "mean_ppo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fced0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/danuo/rocket-meister"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b054a",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/ultimate-guide-for-reinforced-learning-part-1-creating-a-game-956f1f2b0a91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdbc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(25):\n",
    "    result = algo.train()\n",
    "    print(\"episode reward mean:\", _, result['episode_reward_mean'])\n",
    "    mean_ppo.append(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceee586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from rocket_gym import RocketMeister10\n",
    "tune.run(\n",
    "    \"SAC\", # reinforced learning agent\n",
    "    name = \"Training1\",\n",
    "    # to resume training from a checkpoint, set the path accordingly:\n",
    "    # resume = True, # you can resume from checkpoint\n",
    "    # restore = r'.\\ray_results\\Example\\SAC_RocketMeister10_ea992_00000_0_2020-11-11_22-07-33\\checkpoint_3000\\checkpoint-3000',\n",
    "    checkpoint_freq = 100,\n",
    "    checkpoint_at_end = True,\n",
    "    local_dir = r'./ray_results/',\n",
    "    config={\n",
    "        \"env\": RocketMeister10,\n",
    "        \"num_workers\": 30,\n",
    "        \"num_cpus_per_worker\": 0.5,\n",
    "        \"env_config\":{\n",
    "            \"max_steps\": 1000,\n",
    "            \"export_frames\": False,\n",
    "            \"export_states\": False,\n",
    "            # \"reward_mode\": \"continuous\",\n",
    "            # \"env_flipped\": True,\n",
    "            # \"env_flipmode\": True,\n",
    "            }\n",
    "        },\n",
    "    stop = {\n",
    "        \"timesteps_total\": 5_000_000,\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL2)",
   "language": "python",
   "name": "rl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
