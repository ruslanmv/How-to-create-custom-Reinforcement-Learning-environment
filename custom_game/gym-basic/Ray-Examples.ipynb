{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e8d050",
   "metadata": {},
   "source": [
    "### Init Ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "#from ray.rllib.env.env_context import EnvContext\n",
    "#from ray.rllib.algorithms import appo\n",
    "#from ray.rllib.algorithms.appo import APPOConfig\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "    assert ray.is_initialized()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.appo import APPOConfig\n",
    "config = (\n",
    "    APPOConfig()\n",
    "    .rollouts(horizon=10000)\n",
    "    .environment(\n",
    "        MyEnv,\n",
    "        env_config={}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef0dd4",
   "metadata": {},
   "source": [
    "# ray.rllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, ray\n",
    "from ray.rllib.algorithms import ppo\n",
    "#import ray.rllib.agents.ppo as ppo\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611641af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(ray)\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"log_level\"] = \"WARN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = ppo.PPO(env=MyEnv, config=config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f042e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Dashboard URL: http://{}\".format(ray.get_webui_url()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad88e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = PPOConfig()#.rollouts(horizon=200) \n",
    "config={\n",
    "        \"env\": MyEnv,\n",
    "        \"num_workers\": 30,\n",
    "        \"num_cpus_per_worker\": 0.5,\n",
    "        \"env_config\":{\n",
    "            \"max_steps\": 1000,\n",
    "            \"export_frames\": False,\n",
    "            \"export_states\": False,\n",
    "            # \"reward_mode\": \"continuous\",\n",
    "            # \"env_flipped\": True,\n",
    "            # \"env_flipmode\": True,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1647ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo = ppo.PPO(env=MyEnv, config={\"env_config\": {},  # config to pass to env class\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39def459",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ppo = []\n",
    "for _ in range(25):\n",
    "    result = algo.train()\n",
    "    print(\"episode reward mean:\", _, result['episode_reward_mean'])\n",
    "    mean_ppo.append(result['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "tune.run(\n",
    "    \"SAC\", # reinforced learning agent\n",
    "    name = \"Training2\",\n",
    "    checkpoint_freq = 100,\n",
    "    checkpoint_at_end = True,\n",
    "    local_dir = r'./ray_results/',\n",
    "    config={\n",
    "        \"env\": MyEnv,\n",
    "        \"num_workers\": 30,\n",
    "        \"num_cpus_per_worker\": 0.5,\n",
    "        \"env_config\":{\n",
    "            \"max_steps\": 1000,\n",
    "            \"export_frames\": False,\n",
    "            \"export_states\": False,\n",
    "            # \"reward_mode\": \"continuous\",\n",
    "            # \"env_flipped\": True,\n",
    "            # \"env_flipmode\": True,\n",
    "            }\n",
    "        },\n",
    "    stop = {\n",
    "        \"timesteps_total\": 5_000_000,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe50874",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 30\n",
    "s = \"{:3d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:6.2f} saved {}\"\n",
    "\n",
    "for n in range(N_ITER):\n",
    "  result = algo.train()\n",
    "  #file_name = agent.save(CHECKPOINT_ROOT)\n",
    "\n",
    "  print(s.format(\n",
    "    n + 1,\n",
    "    result[\"episode_reward_min\"],\n",
    "    result[\"episode_reward_mean\"],\n",
    "    result[\"episode_reward_max\"],\n",
    "    result[\"episode_len_mean\"],\n",
    "    file_name\n",
    "   ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Gym)",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
