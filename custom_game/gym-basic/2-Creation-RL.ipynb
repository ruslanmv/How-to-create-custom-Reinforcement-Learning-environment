{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0029c888",
   "metadata": {},
   "source": [
    "# 2- Creation of the RL model\n",
    "once we have created the simple enviroment we can pass to the second step that is the creation of the RL Model.\n",
    "\n",
    "First we will consider the gym local enviroment BasicEnv13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f6d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "from pygame import display\n",
    "from pygame.surfarray import array3d\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "training=True\n",
    "\n",
    "df= pd.read_csv(\"test.csv\")\n",
    "feature1=df['island'].max()\n",
    "feature2=df['project'].max()\n",
    "feature3=df['energy_consumption'].max()\n",
    "feature4=df['emp_project'].max()\n",
    "feature5=df['emp_energy_consumption'].max()\n",
    "feature6=df['occupied'].max()\n",
    "\n",
    "max_colors=df['island'].nunique()\n",
    "low_x=int(df['x_coord'].min())\n",
    "high_x=int(df['x_coord'].max())\n",
    "low_y=int(df['y_coord'].min())\n",
    "high_y=int(df['y_coord'].max())\n",
    "possible_clicks=df.shape[0]\n",
    "pos_x=possible_clicks\n",
    "pos_y=possible_clicks\n",
    "max_sit=possible_clicks\n",
    "\n",
    "# get image\n",
    "filepath = \"bg.jpg\"\n",
    "img_bg = Image.open(filepath)\n",
    "# get width and height\n",
    "width = img_bg.width\n",
    "height = img_bg.height\n",
    "  \n",
    "font_color=(0,50,250)\n",
    "WHITE = pygame.Color(255, 255, 255)\n",
    "RED = (200,0,0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "#Load images\n",
    "#To the image we assing a kind of gym object\n",
    "worker_pos=[25,25]\n",
    "#Target image and position\n",
    "position_coordinates=[(50,50),\n",
    "                      (100,50),\n",
    "                      (150,50)]\n",
    "\n",
    "target_rects={}\n",
    "target_images={}\n",
    "counts = df.groupby(['island'])['island'].count()\n",
    "reward_dict=counts.to_dict()\n",
    "\n",
    "def convert_colormap_to_hex(cmap, x, vmin=0, vmax=1):\n",
    "    \"\"\"\n",
    "    Example::\n",
    "        >>> seaborn.palplot(seaborn.color_palette(\"RdBu_r\", 7))\n",
    "        >>> colorMapRGB = seaborn.color_palette(\"RdBu_r\", 61)\n",
    "        >>> colormap = seaborn.blend_palette(colorMapRGB, as_cmap=True, input='rgb')\n",
    "        >>> [convert_colormap_to_hex(colormap, x, vmin=-2, vmax=2) for x in range(-2, 3)]\n",
    "        ['#09386d', '#72b1d3', '#f7f6f5', '#e7866a', '#730421']\n",
    "    \"\"\"\n",
    "    norm = colors.Normalize(vmin, vmax)\n",
    "    color_rgb = plt.cm.get_cmap(cmap)(norm(x))\n",
    "    color_hex = colors.rgb2hex(color_rgb)\n",
    "    return color_hex\n",
    "\n",
    "import  seaborn\n",
    "from matplotlib import colors\n",
    "from PIL import ImageColor\n",
    "colorMapRGB = seaborn.color_palette(\"RdBu_r\", max_colors)\n",
    "colormap = seaborn.blend_palette(colorMapRGB, as_cmap=True, input='rgb')\n",
    "cmap_list=[convert_colormap_to_hex(colormap, x, vmin=-int(max_colors/2)-1, vmax=int(max_colors/2)+1) for x in range(-int(max_colors/2)-1, int(max_colors/2)+1)]\n",
    "\n",
    "\n",
    "class BasicEnv14(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        # There are two actions, first will get reward of 1, second reward of -1. \n",
    "        self.action_space = spaces.Discrete(possible_clicks)\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "    {\"feature1\": gym.spaces.Box(low=0, high=feature1, shape=(1,), dtype=np.uint8),\n",
    "     \"y_position\": gym.spaces.Box(low=low_y, high=high_y, shape=(1,), dtype=np.uint8),\n",
    "     \"x_position\": gym.spaces.Box(low=low_x, high=high_x, shape=(1,), dtype=np.uint8)\n",
    "     }\n",
    "        )\n",
    "        # We inizialize the display\n",
    "        self.frame_size_x = width # high_x\n",
    "        self.frame_size_y = height# high_y\n",
    "        self.game_window = pygame.display.set_mode((self.frame_size_x, self.frame_size_y))  \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.game_window.fill(WHITE)\n",
    "        self.state = None\n",
    "        self.steps = 0\n",
    "        self.worker_pos=[25,25] \n",
    "        self.score = 0\n",
    "        self.steps = 0\n",
    "        action=(0,0)\n",
    "        img = array3d(display.get_surface())\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "        \n",
    "        self.STEP_LIMIT = 1000\n",
    "        #To the image we assing a kind of gym object\n",
    "        self.worker_rect=pygame.draw.circle(self.game_window,BLUE,(self.worker_pos[0], self.worker_pos[1]),6) # DRAW CIRCLE\n",
    "        # Moreover we add a position in the screen display\n",
    "        self.target_rects={} \n",
    "        n_space=df.shape[0]\n",
    "        for num in range(n_space):\n",
    "            targets=int(df['x_coord'][num]), int(df['y_coord'][num])\n",
    "            numero_cluster=df['island'][num]\n",
    "            cmap_color=cmap_list[numero_cluster-1]\n",
    "            target_images[num] = pygame.draw.circle(self.game_window,cmap_color,(targets[0], targets[1]),6) # DRAW CIRCLE\n",
    "            self.target_rects[num] = target_images[num]\n",
    "            #print('Initial positions',targets)\n",
    "            self.target_rects[num].center = targets\n",
    "        # Adding text\n",
    "        pygame.init()\n",
    "        self.font_color=(0,50,250)                                       # Step 1  Color RGB code\n",
    "        self.font_obj=pygame.font.Font(\"C:\\Windows\\Fonts\\Arial.ttf\",20)  # Step 2  Select the font type\n",
    "        # Render the objects\n",
    "        self.text_obj=self.font_obj.render(\"Reward:\",True,self.font_color) # Step 3  Creation of object text        \n",
    "        state, reward, done, info = self.step(action) \n",
    "        return img        \n",
    "        #return state, reward, done, info\n",
    "        \n",
    "    def reward_value(self,worker,target,num):\n",
    "        \n",
    "        #print(Reward check: )\n",
    "        #Check for collision between two rects            \n",
    "        if worker.colliderect(target):\n",
    "            '''\n",
    "            Reward 1 - The more dense is the cluster more reward  \n",
    "            Gives the value of the island   number of seats\n",
    "                0    2\n",
    "                1    4\n",
    "                2    4\n",
    "                3    4\n",
    "                4    1\n",
    "            '''\n",
    "            number_island=df['island'].iloc[num]\n",
    "            reward1=reward_dict[number_island]\n",
    "\n",
    "            '''\n",
    "            Reward 2 - Check if is occupied\n",
    "                0 - occupied\n",
    "                1 - free\n",
    "            '''\n",
    "            is_occupied=df['occupied'].iloc[num]\n",
    "           \n",
    "            '''\n",
    "            Reward 3 - More neighbors more reward\n",
    "            '''\n",
    "            reward3=len(df[(df['island']==number_island) & (df['occupied']==0 )])\n",
    "            reward=(reward1+reward3)*is_occupied\n",
    "            \n",
    "            if is_occupied == 0:\n",
    "                print('is_occupied',is_occupied)\n",
    "            else:\n",
    "                print('reward',reward)\n",
    "            \n",
    "            return reward\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            reward = 0\n",
    "            return reward\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        \n",
    "        \n",
    "        # Check if variable is  tuple\n",
    "        # using type()\n",
    "        #res = type(action) is tuple       \n",
    "        # Inside gym the test need tuples and not int\n",
    "        \n",
    "        if (type(action) == int) or (isinstance(action, np.int64)) :\n",
    "            action_n=int(action)\n",
    "            print('action_n',action_n)\n",
    "            action=int(df['x_coord'][action_n]), int(df['y_coord'][action_n])\n",
    "        \n",
    "        self.worker_pos = action\n",
    "        print('The action is inside step:', action, type(action))\n",
    "        rewards=[]\n",
    "        # We update the state of worker_rect and image\n",
    "        self.update_game_state() \n",
    "        \n",
    "        \n",
    "        # regardless of the action, game is done after a single step\n",
    "        if action != None:\n",
    "            print(\"The action is :\", action)  \n",
    "            n_space=df.shape[0]\n",
    "            for num in range(n_space):\n",
    "                reward = self.reward_value(self.worker_rect,self.target_rects[num],num)\n",
    "                #print('num',num)\n",
    "\n",
    "                if reward !=0:\n",
    "        \n",
    "                    #print(\"The worker rect is :\",self.worker_rect)\n",
    "                    #print(\"The target rect is :\",self.target_rects[num] ) \n",
    "                    rewards.append(reward)\n",
    "                    #print(\"rewards\",rewards)\n",
    "                    \n",
    "        if len(rewards) < 1:\n",
    "            reward=0\n",
    "        else:\n",
    "            reward=rewards[0]\n",
    "        \n",
    "\n",
    "        if training == False:\n",
    "            # Render the objects\n",
    "            self.text_obj=self.font_obj.render(\"Reward :\" + str(reward),True,self.font_color) # Step 3  Creation of object text\n",
    "            #Display text\n",
    "            self.game_window.blit(self.text_obj,(300,0))         \n",
    "            \n",
    "              \n",
    "        img = self.get_image_array_from_game()\n",
    "        #done = True\n",
    "        info = {}\n",
    "        reward, done = self.game_over(reward) \n",
    "        print('reward: {}, done: {}, info: {}, step: {}'.format(reward, done, info,self.steps))\n",
    "        self.steps += 1\n",
    "        return img, reward, done, info\n",
    "    \n",
    "    def worker_step(self,event):   \n",
    "        '''\n",
    "        Takes human keyboard event and then returns it as an action string\n",
    "        '''\n",
    "        action = None\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "            \n",
    "        #Move based on mouse clicks\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "\n",
    "            #'CLICK'\n",
    "            action = mouse_x, mouse_y\n",
    "        \n",
    "        #Drag the object when the mouse button is clicked\n",
    "        if event.type == pygame.MOUSEMOTION and event.buttons[0] == 1:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "    \n",
    "            #'CLICK'\n",
    "            action = mouse_x, mouse_y\n",
    "        \n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "        \n",
    "            # Esc -> Create event to quit the game\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                pygame.event.post(pygame.event.Event(pygame.QUIT))                       \n",
    "        return action    \n",
    "    \n",
    "    def update_game_state(self):\n",
    "        #We fill the screen to white\n",
    "        if training == True:\n",
    "            self.game_window.fill(WHITE)\n",
    "        else:    \n",
    "            bg = pygame.image.load(\"bg.jpg\")\n",
    "            #Give a background color to the display\n",
    "            self.game_window.blit(bg, (0, 0))\n",
    "        # -------------WORKER--------------\n",
    "        \n",
    "        #if type(self.worker_pos) == int:\n",
    "        #    action_n=self.worker_pos\n",
    "        #    print('action_n in update is:',action_n)\n",
    "        #    action=int(df['x_coord'][action_n]), int(df['y_coord'][action_n])\n",
    "        #    self.worker_pos=action    \n",
    "        \n",
    "        \n",
    "        print('self.worker_pos:',self.worker_pos)\n",
    "        print('worker_pos',self.worker_pos[0],self.worker_pos[1])\n",
    "        \n",
    "        self.worker_rect.x=self.worker_pos[0]\n",
    "        self.worker_rect.y=self.worker_pos[1]\n",
    "        #Draw rectangles to represent the rect's of each object\n",
    "        self.worker_rect=pygame.draw.circle(self.game_window,BLUE,(self.worker_rect.x,self.worker_rect.y),6) # DRAW CIRCLE\n",
    "        \n",
    "        #-------------- Multiple points TARGETS------------------\n",
    "        n_space=df.shape[0]\n",
    "        for num in range(n_space):\n",
    "            numero_cluster=df['island'][num]\n",
    "            cmap_color=cmap_list[numero_cluster-1]\n",
    "            occupied=df['occupied'][num]\n",
    "            if occupied == 0:\n",
    "                color=RED\n",
    "            else:\n",
    "                color=GREEN\n",
    "            pygame.draw.circle(self.game_window,color,(self.target_rects[num].x,self.target_rects[num].y),6) # DRAW CIRCLE\n",
    "            \n",
    "    def get_image_array_from_game(self):\n",
    "        img = array3d(display.get_surface())\n",
    "        #Preprocessing of channels ( needed for tensorflow)\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "        return img    \n",
    "   \n",
    "    def render(self, mode='human'):\n",
    "        if mode == \"human\":\n",
    "            display.update()        \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def game_over(self, reward):\n",
    "        if reward == 0:\n",
    "            return -1, True\n",
    "    \n",
    "        if self.steps >= 1000:\n",
    "            return 0, True\n",
    "        \n",
    "        return reward, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29555713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n"
     ]
    }
   ],
   "source": [
    "# method 1 - use local test class\n",
    "env = BasicEnv14()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e6474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eaa89b0b00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1a9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 1\n",
      "Reward = 2 with action = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eaa88ef320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action_n = env.action_space.sample()\n",
    "state, reward, done, info = env.step(action_n)\n",
    "print(\"Reward = {} with action = {}\".format(reward,action_n))\n",
    "#print(state)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9c2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_n 1\n",
      "(521, 311)\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "Reward = 5 with action = (521, 311)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eaa896b4e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action_n = env.action_space.sample()\n",
    "print('action_n',action_n)\n",
    "action=int(df['x_coord'][action_n]), int(df['y_coord'][action_n])\n",
    "print(action)\n",
    "state, reward, done, info = env.step(action)\n",
    "print(\"Reward = {} with action = {}\".format(reward,action))\n",
    "#print(state)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf6dc60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 609, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fd22aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 84, 84)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 3\n",
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3481c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_observation_test(observation):\n",
    "    if type(observation) == type(None):\n",
    "        whiteFrame= 255 * np.ones((640,480,3), np.uint8)\n",
    "        observation=whiteFrame\n",
    "    # First convert the numpy array to a PIL Image\n",
    "    img = Image.fromarray(observation)\n",
    "    # Then resize the image\n",
    "    img = img.resize(IMG_SHAPE)\n",
    "    # And convert it to grayscale  (The L stands for luminance)\n",
    "    #img = img.convert(\"L\")\n",
    "    # Convert the image back to a numpy array and finally return the image\n",
    "    img = np.array(img)\n",
    "    return img.astype('uint8')  # saves storage in experience memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a5a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_observation_test(None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cab3473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_observation_test(state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67c1da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # To transform the image in the Processor\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Convolutional Backbone Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Keras-RL\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f8aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc261eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7180fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4daac8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        # First convert the numpy array to a PIL Image\n",
    "        img = Image.fromarray(observation)\n",
    "        # Then resize the image\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        # And convert it to grayscale  (The L stands for luminance)\n",
    "        img = img.convert(\"L\")\n",
    "        # Convert the image back to a numpy array and finally return the image\n",
    "        img = np.array(img)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "\n",
    "        # We divide the observations by 255 to compress it into the intervall [0, 1].\n",
    "        # This supports the training of the network\n",
    "        # We perform this operation here to save memory.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42785eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessorFix(Processor):\n",
    "    def process_observation(self,observation):\n",
    "        if type(observation) == type(None):\n",
    "            whiteFrame= 255 * np.ones((640,480,3), np.uint8)\n",
    "            observation=whiteFrame\n",
    "        # First convert the numpy array to a PIL Image\n",
    "        img = Image.fromarray(observation)\n",
    "        # Then resize the image\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        # And convert it to grayscale  (The L stands for luminance)\n",
    "        #img = img.convert(\"L\")\n",
    "        # Convert the image back to a numpy array and finally return the image\n",
    "        img = np.array(img)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We divide the observations by 255 to compress it into the intervall [0, 1].\n",
    "        # This supports the training of the network\n",
    "        # We perform this operation here to save memory.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186761e4",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "**NOTE: Depending on your custom environment, this model will vary greatly, try reading papers that are solving similar problems to your own!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096ac5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 84, 84)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f9ad2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute (Permute)           (None, 84, 84, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 20, 20, 32)        6176      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,692,340\n",
      "Trainable params: 1,692,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35dbd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=False\n",
    "if model2:\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Conv2D, Flatten\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))  # (28,28,1)))\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_actions, activation='softmax'))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e5bac",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071a2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfe38446",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8090bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e33f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "              train_interval=4, delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1581c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb0c7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = 'test_dqn_worker_weights.h5f'\n",
    "checkpoint_weights_filename = 'test_dqn_' + \"worker\" + '_weights_{step}.h5f'\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecde7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_steps=1500000\n",
    "dqn.fit(env, nb_steps=1500, callbacks=[checkpoint_callback], log_interval=100000, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f0e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "795b9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eead6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final final weights were stored in test_dqn_worker_weights.h5f\n"
     ]
    }
   ],
   "source": [
    "print('Final final weights were stored in', weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3c63180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "dqn.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b10e0ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 1: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 2: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 3: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 4: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 5: reward: -1.000, steps: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eab3d25940>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0ae45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfaee3b1",
   "metadata": {},
   "source": [
    "Example 2\n",
    "\n",
    "https://www.programcreek.com/python/?code=PacktPublishing%2FDeep-Learning-Quick-Reference%2FDeep-Learning-Quick-Reference-master%2FChapter12%2Fdqn_breakout_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a600ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b60df24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78381eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "env.seed(42)\n",
    "num_actions = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1243af40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8b74b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(state_size, num_actions):\n",
    "    input_shape = (3,) + state_size\n",
    "    model = Sequential()\n",
    "    model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        # (width, height, channels)\n",
    "        model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "    elif K.image_dim_ordering() == 'th':\n",
    "        # (channels, width, height)\n",
    "        model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "    else:\n",
    "        raise RuntimeError('Unknown image_dim_ordering.')\n",
    "    '''    \n",
    "    \n",
    "\n",
    "    model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (4, 4), strides=(2, 2),kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1, 1),kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_actions))\n",
    "    model.add(Activation('linear'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d02b651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute_1 (Permute)         (None, 84, 84, 3)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 32)        6176      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,692,340\n",
      "Trainable params: 1,692,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model(INPUT_SHAPE, num_actions)\n",
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39120525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        \n",
    "        \n",
    "       # if type(observation) == type(None):\n",
    "       #     whiteFrame= 255 * np.ones((640,480,3), np.uint8)\n",
    "       #     observation=whiteFrame\n",
    "            \n",
    "        assert observation.ndim == 3  # (height, width, channel)\n",
    "        img = Image.fromarray(observation)\n",
    "        img = img.resize((84, 84), Image.ANTIALIAS).convert('L')  # resize and convert to grayscale\n",
    "        processed_observation = np.array(img)\n",
    "        assert processed_observation.shape == (84, 84)\n",
    "        return processed_observation.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        # We could perform this processing step in `process_observation`. In this case, however,\n",
    "        # we would need to store a `float32` array instead, which is 4x more memory intensive than\n",
    "        # an `uint8` array. This matters if we store 1M observations.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44a850b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AtariProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc3aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6977d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_callbacks(env_name):\n",
    "    checkpoint_weights_filename = 'dqn_' + env_name + '_weights_{step}.h5f'\n",
    "    log_filename = 'dqn_{}_log.json'.format(env_name)\n",
    "    callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "    callbacks += [FileLogger(log_filename, interval=100)]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baed3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model, nb_actions=num_actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "               train_interval=4, delta_clip=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d3acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'Test-RL-v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "025665b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMAGANAV\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(Adam(lr=.00025), metrics=['mae'])\n",
    "callbacks = build_callbacks(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a327fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 150 steps ...\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "Interval 1 (0 steps performed)\n",
      "action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "     1/100000 [..............................] - ETA: 3:21:36 - reward: 1.0000action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 3\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "     4/100000 [..............................] - ETA: 34:27 - reward: 0.5000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMAGANAV\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "     6/100000 [..............................] - ETA: 44:00 - reward: 0.6667action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "     8/100000 [..............................] - ETA: 48:34 - reward: 0.5000action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "    10/100000 [..............................] - ETA: 47:57 - reward: 0.6000action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    12/100000 [..............................] - ETA: 52:34 - reward: 0.5000action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "    14/100000 [..............................] - ETA: 52:18 - reward: 0.4286The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    15/100000 [..............................] - ETA: 55:21 - reward: 0.4667action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 1\n",
      "    18/100000 [..............................] - ETA: 55:11 - reward: 0.4444action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "    20/100000 [..............................] - ETA: 53:56 - reward: 0.5000action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    22/100000 [..............................] - ETA: 55:04 - reward: 0.4545action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    24/100000 [..............................] - ETA: 55:34 - reward: 0.3333The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 1\n",
      "    25/100000 [..............................] - ETA: 57:16 - reward: 0.3600action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "    28/100000 [..............................] - ETA: 54:55 - reward: 0.4286action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 5\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    30/100000 [..............................] - ETA: 55:37 - reward: 0.4000action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    32/100000 [..............................] - ETA: 55:52 - reward: 0.3750action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    35/100000 [..............................] - ETA: 54:22 - reward: 0.3714The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    36/100000 [..............................] - ETA: 55:32 - reward: 0.3333The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    37/100000 [..............................] - ETA: 56:27 - reward: 0.2973The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    38/100000 [..............................] - ETA: 57:18 - reward: 0.3158action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 3\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "    41/100000 [..............................] - ETA: 55:48 - reward: 0.3659action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 5\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 1\n",
      "    43/100000 [..............................] - ETA: 56:14 - reward: 0.3488action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 3\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "    46/100000 [..............................] - ETA: 55:13 - reward: 0.3913action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 5\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 6\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    49/100000 [..............................] - ETA: 55:16 - reward: 0.3878action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    51/100000 [..............................] - ETA: 55:42 - reward: 0.3333The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    52/100000 [..............................] - ETA: 56:22 - reward: 0.3077The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    53/100000 [..............................] - ETA: 56:57 - reward: 0.3208action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 3\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "    56/100000 [..............................] - ETA: 55:47 - reward: 0.3214The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    58/100000 [..............................] - ETA: 56:38 - reward: 0.3103action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    60/100000 [..............................] - ETA: 56:42 - reward: 0.3000action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    63/100000 [..............................] - ETA: 56:30 - reward: 0.2698The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "    65/100000 [..............................] - ETA: 56:37 - reward: 0.2923action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    68/100000 [..............................] - ETA: 56:20 - reward: 0.2647The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 19\n",
      "The action is inside step: (336, 137) <class 'tuple'>\n",
      "self.worker_pos: (336, 137)\n",
      "worker_pos 336 137\n",
      "The action is : (336, 137)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "    70/100000 [..............................] - ETA: 56:19 - reward: 0.2857action_n 17\n",
      "The action is inside step: (87, 169) <class 'tuple'>\n",
      "self.worker_pos: (87, 169)\n",
      "worker_pos 87 169\n",
      "The action is : (87, 169)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 17\n",
      "The action is inside step: (87, 169) <class 'tuple'>\n",
      "self.worker_pos: (87, 169)\n",
      "worker_pos 87 169\n",
      "The action is : (87, 169)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    72/100000 [..............................] - ETA: 56:27 - reward: 0.2500The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    73/100000 [..............................] - ETA: 56:50 - reward: 0.2603action_n 19\n",
      "The action is inside step: (336, 137) <class 'tuple'>\n",
      "self.worker_pos: (336, 137)\n",
      "worker_pos 336 137\n",
      "The action is : (336, 137)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "    76/100000 [..............................] - ETA: 55:59 - reward: 0.2632The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 1\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "    78/100000 [..............................] - ETA: 56:05 - reward: 0.2564The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 1\n",
      "    79/100000 [..............................] - ETA: 56:31 - reward: 0.2658action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    81/100000 [..............................] - ETA: 56:34 - reward: 0.2593action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 17\n",
      "The action is inside step: (87, 169) <class 'tuple'>\n",
      "self.worker_pos: (87, 169)\n",
      "worker_pos 87 169\n",
      "The action is : (87, 169)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    83/100000 [..............................] - ETA: 56:38 - reward: 0.2289The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "    85/100000 [..............................] - ETA: 56:39 - reward: 0.2235The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    86/100000 [..............................] - ETA: 57:01 - reward: 0.2326action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 2\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 4\n",
      "    89/100000 [..............................] - ETA: 56:16 - reward: 0.2584action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 5\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    91/100000 [..............................] - ETA: 56:19 - reward: 0.2527action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "    94/100000 [..............................] - ETA: 56:14 - reward: 0.2553action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    96/100000 [..............................] - ETA: 56:16 - reward: 0.2292The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "    98/100000 [..............................] - ETA: 56:41 - reward: 0.2041The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "   100/100000 [..............................] - ETA: 57:10 - reward: 0.1800The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   101/100000 [..............................] - ETA: 57:28 - reward: 0.1881action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 2\n",
      "action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 3\n",
      "action_n 8\n",
      "The action is inside step: (387, 254) <class 'tuple'>\n",
      "self.worker_pos: (387, 254)\n",
      "worker_pos 387 254\n",
      "The action is : (387, 254)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "   104/100000 [..............................] - ETA: 56:53 - reward: 0.2115action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 5\n",
      "action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 6\n",
      "action_n 2\n",
      "The action is inside step: (188, 298) <class 'tuple'>\n",
      "self.worker_pos: (188, 298)\n",
      "worker_pos 188 298\n",
      "The action is : (188, 298)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 7\n",
      "   107/100000 [..............................] - ETA: 56:23 - reward: 0.2150The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   108/100000 [..............................] - ETA: 56:40 - reward: 0.2222action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "   111/100000 [..............................] - ETA: 56:07 - reward: 0.2432action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 5\n",
      "action_n 1\n",
      "The action is inside step: (521, 311) <class 'tuple'>\n",
      "self.worker_pos: (521, 311)\n",
      "worker_pos 521 311\n",
      "The action is : (521, 311)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 6\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 7\n",
      "   114/100000 [..............................] - ETA: 55:35 - reward: 0.2632action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 8\n",
      "action_n 5\n",
      "The action is inside step: (507, 278) <class 'tuple'>\n",
      "self.worker_pos: (507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 9\n",
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 10\n",
      "   117/100000 [..............................] - ETA: 55:06 - reward: 0.2821action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 11\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 6\n",
      "The action is inside step: (542, 262) <class 'tuple'>\n",
      "self.worker_pos: (542, 262)\n",
      "worker_pos 542 262\n",
      "The action is : (542, 262)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   119/100000 [..............................] - ETA: 55:12 - reward: 0.2773action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 14\n",
      "The action is inside step: (372, 172) <class 'tuple'>\n",
      "self.worker_pos: (372, 172)\n",
      "worker_pos 372 172\n",
      "The action is : (372, 172)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   121/100000 [..............................] - ETA: 55:00 - reward: 0.2893action_n 7\n",
      "The action is inside step: (456, 257) <class 'tuple'>\n",
      "self.worker_pos: (456, 257)\n",
      "worker_pos 456 257\n",
      "The action is : (456, 257)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 4\n",
      "action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 5\n",
      "   123/100000 [..............................] - ETA: 54:52 - reward: 0.3008action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 6\n",
      "action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 7\n",
      "   125/100000 [..............................] - ETA: 54:48 - reward: 0.3120action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 8\n",
      "action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 9\n",
      "   127/100000 [..............................] - ETA: 54:39 - reward: 0.3071The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "   128/100000 [..............................] - ETA: 55:01 - reward: 0.2969The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   129/100000 [..............................] - ETA: 55:23 - reward: 0.3023action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "   131/100000 [..............................] - ETA: 55:15 - reward: 0.3130action_n 4\n",
      "The action is inside step: (423, 290) <class 'tuple'>\n",
      "self.worker_pos: (423, 290)\n",
      "worker_pos 423 290\n",
      "The action is : (423, 290)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   133/100000 [..............................] - ETA: 55:29 - reward: 0.3083action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "   135/100000 [..............................] - ETA: 55:47 - reward: 0.2889The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   136/100000 [..............................] - ETA: 56:20 - reward: 0.2941action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 9\n",
      "The action is inside step: (423, 223) <class 'tuple'>\n",
      "self.worker_pos: (423, 223)\n",
      "worker_pos 423 223\n",
      "The action is : (423, 223)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   138/100000 [..............................] - ETA: 56:39 - reward: 0.2899action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 0\n",
      "The action is inside step: (18, 694) <class 'tuple'>\n",
      "self.worker_pos: (18, 694)\n",
      "worker_pos 18 694\n",
      "The action is : (18, 694)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "   140/100000 [..............................] - ETA: 56:51 - reward: 0.2714The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 15\n",
      "The action is inside step: (303, 171) <class 'tuple'>\n",
      "self.worker_pos: (303, 171)\n",
      "worker_pos 303 171\n",
      "The action is : (303, 171)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 1\n",
      "   141/100000 [..............................] - ETA: 57:08 - reward: 0.2766action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 2\n",
      "action_n 19\n",
      "The action is inside step: (336, 137) <class 'tuple'>\n",
      "self.worker_pos: (336, 137)\n",
      "worker_pos 336 137\n",
      "The action is : (336, 137)\n",
      "reward 5\n",
      "reward: 5, done: False, info: {}, step: 3\n",
      "   143/100000 [..............................] - ETA: 56:59 - reward: 0.2867action_n 17\n",
      "The action is inside step: (87, 169) <class 'tuple'>\n",
      "self.worker_pos: (87, 169)\n",
      "worker_pos 87 169\n",
      "The action is : (87, 169)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 4\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 18\n",
      "The action is inside step: (508, 138) <class 'tuple'>\n",
      "self.worker_pos: (508, 138)\n",
      "worker_pos 508 138\n",
      "The action is : (508, 138)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 1\n",
      "   145/100000 [..............................] - ETA: 57:09 - reward: 0.2828action_n 11\n",
      "The action is inside step: (337, 204) <class 'tuple'>\n",
      "self.worker_pos: (337, 204)\n",
      "worker_pos 337 204\n",
      "The action is : (337, 204)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 2\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 10\n",
      "The action is inside step: (506, 209) <class 'tuple'>\n",
      "self.worker_pos: (506, 209)\n",
      "worker_pos 506 209\n",
      "The action is : (506, 209)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 1\n",
      "   147/100000 [..............................] - ETA: 57:21 - reward: 0.2789action_n 12\n",
      "The action is inside step: (472, 175) <class 'tuple'>\n",
      "self.worker_pos: (472, 175)\n",
      "worker_pos 472 175\n",
      "The action is : (472, 175)\n",
      "reward 2\n",
      "reward: 2, done: False, info: {}, step: 2\n",
      "action_n 13\n",
      "The action is inside step: (544, 174) <class 'tuple'>\n",
      "self.worker_pos: (544, 174)\n",
      "worker_pos 544 174\n",
      "The action is : (544, 174)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   149/100000 [..............................] - ETA: 57:12 - reward: 0.2752The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 16\n",
      "The action is inside step: (423, 169) <class 'tuple'>\n",
      "self.worker_pos: (423, 169)\n",
      "worker_pos 423 169\n",
      "The action is : (423, 169)\n",
      "reward 1\n",
      "reward: 1, done: False, info: {}, step: 1\n",
      "   150/100000 [..............................] - ETA: 57:29 - reward: 0.2800done, took 5.298 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29725a4c390>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=150, callbacks=callbacks, log_interval=100000, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe6c10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "#dqn.load_weights('Test-RL-v2_1750000.h5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f924300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 1: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 2: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 3: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 4: reward: -1.000, steps: 1\n",
      "The action is inside step: (0, 0) <class 'tuple'>\n",
      "self.worker_pos: (0, 0)\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward: -1, done: True, info: {}, step: 0\n",
      "action_n 3\n",
      "The action is inside step: (557, 294) <class 'tuple'>\n",
      "self.worker_pos: (557, 294)\n",
      "worker_pos 557 294\n",
      "The action is : (557, 294)\n",
      "is_occupied 0\n",
      "reward: -1, done: True, info: {}, step: 1\n",
      "Episode 5: reward: -1.000, steps: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2972531e358>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b9d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Gym)",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
