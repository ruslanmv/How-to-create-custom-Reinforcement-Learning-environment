{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0029c888",
   "metadata": {},
   "source": [
    "# 2- Creation of the RL model\n",
    "once we have created the simple enviroment we can pass to the second step that is the creation of the RL Model.\n",
    "\n",
    "First we will consider the gym local enviroment BasicEnv13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f6d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "from pygame import display\n",
    "from pygame.surfarray import array3d\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "training=True\n",
    "\n",
    "df= pd.read_csv(\"test.csv\")\n",
    "feature1=df['island'].max()\n",
    "feature2=df['project'].max()\n",
    "feature3=df['energy_consumption'].max()\n",
    "feature4=df['emp_project'].max()\n",
    "feature5=df['emp_energy_consumption'].max()\n",
    "feature6=df['occupied'].max()\n",
    "\n",
    "max_colors=df['island'].nunique()\n",
    "low_x=int(df['x_coord'].min())\n",
    "high_x=int(df['x_coord'].max())\n",
    "low_y=int(df['y_coord'].min())\n",
    "high_y=int(df['y_coord'].max())\n",
    "possible_clicks=df.shape[0]\n",
    "pos_x=possible_clicks\n",
    "pos_y=possible_clicks\n",
    "max_sit=possible_clicks\n",
    "\n",
    "# get image\n",
    "filepath = \"bg.jpg\"\n",
    "img_bg = Image.open(filepath)\n",
    "# get width and height\n",
    "width = img_bg.width\n",
    "height = img_bg.height\n",
    "  \n",
    "font_color=(0,50,250)\n",
    "WHITE = pygame.Color(255, 255, 255)\n",
    "RED = (200,0,0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "#Load images\n",
    "#To the image we assing a kind of gym object\n",
    "worker_pos=[25,25]\n",
    "#Target image and position\n",
    "position_coordinates=[(50,50),\n",
    "                      (100,50),\n",
    "                      (150,50)]\n",
    "\n",
    "target_rects={}\n",
    "target_images={}\n",
    "counts = df.groupby(['island'])['island'].count()\n",
    "reward_dict=counts.to_dict()\n",
    "\n",
    "def convert_colormap_to_hex(cmap, x, vmin=0, vmax=1):\n",
    "    \"\"\"\n",
    "    Example::\n",
    "        >>> seaborn.palplot(seaborn.color_palette(\"RdBu_r\", 7))\n",
    "        >>> colorMapRGB = seaborn.color_palette(\"RdBu_r\", 61)\n",
    "        >>> colormap = seaborn.blend_palette(colorMapRGB, as_cmap=True, input='rgb')\n",
    "        >>> [convert_colormap_to_hex(colormap, x, vmin=-2, vmax=2) for x in range(-2, 3)]\n",
    "        ['#09386d', '#72b1d3', '#f7f6f5', '#e7866a', '#730421']\n",
    "    \"\"\"\n",
    "    norm = colors.Normalize(vmin, vmax)\n",
    "    color_rgb = plt.cm.get_cmap(cmap)(norm(x))\n",
    "    color_hex = colors.rgb2hex(color_rgb)\n",
    "    return color_hex\n",
    "\n",
    "import  seaborn\n",
    "from matplotlib import colors\n",
    "from PIL import ImageColor\n",
    "colorMapRGB = seaborn.color_palette(\"RdBu_r\", max_colors)\n",
    "colormap = seaborn.blend_palette(colorMapRGB, as_cmap=True, input='rgb')\n",
    "cmap_list=[convert_colormap_to_hex(colormap, x, vmin=-int(max_colors/2)-1, vmax=int(max_colors/2)+1) for x in range(-int(max_colors/2)-1, int(max_colors/2)+1)]\n",
    "\n",
    "\n",
    "class BasicEnv13(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        # There are two actions, first will get reward of 1, second reward of -1. \n",
    "        self.action_space = spaces.Discrete(possible_clicks)\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "    {\"feature1\": gym.spaces.Box(low=0, high=feature1, shape=(1,), dtype=np.uint8),\n",
    "     \"y_position\": gym.spaces.Box(low=low_y, high=high_y, shape=(1,), dtype=np.uint8),\n",
    "     \"x_position\": gym.spaces.Box(low=low_x, high=high_x, shape=(1,), dtype=np.uint8)\n",
    "     }\n",
    "        )\n",
    "        # We inizialize the display\n",
    "        self.frame_size_x = width # high_x\n",
    "        self.frame_size_y = height# high_y\n",
    "        self.game_window = pygame.display.set_mode((self.frame_size_x, self.frame_size_y))   \n",
    "        \n",
    "        #Load images\n",
    "        #To the image we assing a kind of gym object\n",
    "        self.worker_pos=[25,25]\n",
    "        self.worker_rect=pygame.draw.circle(self.game_window,BLUE,(self.worker_pos[0], self.worker_pos[1]),6) # DRAW CIRCLE\n",
    "\n",
    "        # Moreover we add a position in the screen display\n",
    "\n",
    "        self.target_rects={} \n",
    "        n_space=df.shape[0]\n",
    "        for num in range(n_space):\n",
    "            targets=int(df['x_coord'][num]), int(df['y_coord'][num])\n",
    "            numero_cluster=df['island'][num]\n",
    "            cmap_color=cmap_list[numero_cluster-1]\n",
    "            target_images[num] = pygame.draw.circle(self.game_window,cmap_color,(targets[0], targets[1]),6) # DRAW CIRCLE\n",
    "            self.target_rects[num] = target_images[num]\n",
    "            #print('Initial positions',targets)\n",
    "            self.target_rects[num].center = targets\n",
    "    \n",
    "        self.state = None\n",
    "                \n",
    "        # Adding text\n",
    "        pygame.init()\n",
    "        self.font_color=(0,50,250)                                       # Step 1  Color RGB code\n",
    "        self.font_obj=pygame.font.Font(\"C:\\Windows\\Fonts\\Arial.ttf\",20)  # Step 2  Select the font type\n",
    "        # Render the objects\n",
    "        self.text_obj=self.font_obj.render(\"Reward:\",True,self.font_color) # Step 3  Creation of object text\n",
    "        \n",
    "    def reward_value(self,worker,target,num):\n",
    "        \n",
    "        #print(Reward check: )\n",
    "        #Check for collision between two rects            \n",
    "        if worker.colliderect(target):\n",
    "            '''\n",
    "            Reward 1 - The more dense is the cluster more reward  \n",
    "            Gives the value of the island   number of seats\n",
    "                0    2\n",
    "                1    4\n",
    "                2    4\n",
    "                3    4\n",
    "                4    1\n",
    "            '''\n",
    "            number_island=df['island'].iloc[num]\n",
    "            reward1=reward_dict[number_island]\n",
    "\n",
    "            '''\n",
    "            Reward 2 - Check if is occupied\n",
    "                0 - occupied\n",
    "                1 - free\n",
    "            '''\n",
    "            is_occupied=df['occupied'].iloc[num]\n",
    "           \n",
    "            '''\n",
    "            Reward 3 - More neighbors more reward\n",
    "            '''\n",
    "            reward3=len(df[(df['island']==number_island) & (df['occupied']==0 )])\n",
    "            reward=(reward1+reward3)*is_occupied\n",
    "            \n",
    "            if is_occupied == 0:\n",
    "                print('is_occupied',is_occupied)\n",
    "            else:\n",
    "                print('reward',reward)\n",
    "            \n",
    "            return reward\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            reward = 0\n",
    "            return reward\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        self.worker_pos = action\n",
    "        # We update the state with an image\n",
    "        self.update_game_state()\n",
    "\n",
    "        rewards=[]\n",
    "        # regardless of the action, game is done after a single step\n",
    "        if action != None:\n",
    "            print(\"The action is :\", action)\n",
    "            \n",
    "            n_space=df.shape[0]\n",
    "            for num in range(n_space):\n",
    "                reward = self.reward_value(self.worker_rect,self.target_rects[num],num)\n",
    "                #print('num',num)\n",
    "\n",
    "                if reward !=0:\n",
    "                    \n",
    "                    print(\"The worker rect is :\",self.worker_rect)\n",
    "                    print(\"The target rect is :\",self.target_rects[num] ) \n",
    "                    rewards.append(reward)\n",
    "                    print(\"rewards\",rewards)\n",
    "                    \n",
    "        if len(rewards) < 1:\n",
    "            reward=0\n",
    "        else:\n",
    "            reward=rewards[0]\n",
    "        \n",
    "\n",
    "        if training == False:\n",
    "            # Render the objects\n",
    "            self.text_obj=self.font_obj.render(\"Reward :\" + str(reward),True,self.font_color) # Step 3  Creation of object text\n",
    "            #Display text\n",
    "            self.game_window.blit(self.text_obj,(300,0))         \n",
    "\n",
    "\n",
    "        img = self.get_image_array_from_game()\n",
    "        state=img\n",
    "        \n",
    "        done = True\n",
    "        info = {}\n",
    "        \n",
    "        print('reward, done, info',reward, done, info)\n",
    "        return state, reward, done, info\n",
    "    \n",
    "    def worker_step(self,event):   \n",
    "        '''\n",
    "        Takes human keyboard event and then returns it as an action string\n",
    "        '''\n",
    "        action = None\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "            \n",
    "        #Move based on mouse clicks\n",
    "        if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "\n",
    "            #'CLICK'\n",
    "            action = mouse_x, mouse_y\n",
    "        \n",
    "        #Drag the object when the mouse button is clicked\n",
    "        if event.type == pygame.MOUSEMOTION and event.buttons[0] == 1:\n",
    "            #print(event)\n",
    "            mouse_x = event.pos[0]\n",
    "            mouse_y = event.pos[1]\n",
    "    \n",
    "            #'CLICK'\n",
    "            action = mouse_x, mouse_y\n",
    "        \n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "        \n",
    "            # Esc -> Create event to quit the game\n",
    "            if event.key == pygame.K_ESCAPE:\n",
    "                pygame.event.post(pygame.event.Event(pygame.QUIT))                       \n",
    "        return action    \n",
    "    \n",
    "    def update_game_state(self):\n",
    "        #We fill the screen to white\n",
    "        if training == True:\n",
    "            self.game_window.fill(WHITE)\n",
    "        else:    \n",
    "            bg = pygame.image.load(\"bg.jpg\")\n",
    "            #Give a background color to the display\n",
    "            self.game_window.blit(bg, (0, 0))\n",
    "            \n",
    "        \n",
    "        # -------------WORKER--------------\n",
    "        \n",
    "        print('worker_pos',self.worker_pos[0],self.worker_pos[1])\n",
    "        self.worker_rect.x=self.worker_pos[0]\n",
    "        self.worker_rect.y=self.worker_pos[1]\n",
    "        #Draw rectangles to represent the rect's of each object\n",
    "        self.worker_rect=pygame.draw.circle(self.game_window,BLUE,(self.worker_rect.x,self.worker_rect.y),6) # DRAW CIRCLE\n",
    "        \n",
    "        #-------------- Multiple points TARGETS------------------\n",
    "        n_space=df.shape[0]\n",
    "        for num in range(n_space):\n",
    "            numero_cluster=df['island'][num]\n",
    "            cmap_color=cmap_list[numero_cluster-1]\n",
    "            occupied=df['occupied'][num]\n",
    "            if occupied == 0:\n",
    "                color=RED\n",
    "            else:\n",
    "                color=GREEN\n",
    "            pygame.draw.circle(self.game_window,color,(self.target_rects[num].x,self.target_rects[num].y),6) # DRAW CIRCLE\n",
    "            \n",
    "    def get_image_array_from_game(self):\n",
    "        img = array3d(display.get_surface())\n",
    "        #Preprocessing of channels ( needed for tensorflow)\n",
    "        img = np.swapaxes(img, 0, 1)\n",
    "        return img    \n",
    "    def reset(self):\n",
    "        action=(0,0)\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        if mode == \"human\":\n",
    "            display.update()        \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9c2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward, done, info 0 True {}\n",
      "action_n 5\n",
      "(507, 278)\n",
      "worker_pos 507 278\n",
      "The action is : (507, 278)\n",
      "reward 5\n",
      "The worker rect is : <rect(501, 272, 12, 12)>\n",
      "The target rect is : <rect(501, 272, 12, 12)>\n",
      "rewards [5]\n",
      "reward, done, info 5 True {}\n",
      "Reward = 5 with action = (507, 278)\n",
      "5 True {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2953a499e48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# method 1 - use local test class\n",
    "env = BasicEnv13()\n",
    "env.reset()\n",
    "action_n = env.action_space.sample()\n",
    "print('action_n',action_n)\n",
    "action=int(df['x_coord'][action_n]), int(df['y_coord'][action_n])\n",
    "print(action)\n",
    "state, reward, done, info = env.step(action)\n",
    "print(\"Reward = {} with action = {}\".format(reward,action))\n",
    "#print(state)\n",
    "import matplotlib.pyplot as plt\n",
    "print(reward, done, info)\n",
    "plt.figure()\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6dc60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 609, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14da5619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2953a846f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "whiteFrame = 255 * np.ones((640,480,3), np.uint8)\n",
    "plt.imshow(whiteFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fd22aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3481c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_observation_test(observation):\n",
    "    if type(observation) == type(None):\n",
    "        whiteFrame= 255 * np.ones((640,480,3), np.uint8)\n",
    "        observation=whiteFrame\n",
    "    # First convert the numpy array to a PIL Image\n",
    "    img = Image.fromarray(observation)\n",
    "    # Then resize the image\n",
    "    img = img.resize(IMG_SHAPE)\n",
    "    # And convert it to grayscale  (The L stands for luminance)\n",
    "    #img = img.convert(\"L\")\n",
    "    # Convert the image back to a numpy array and finally return the image\n",
    "    img = np.array(img)\n",
    "    return img.astype('uint8')  # saves storage in experience memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a5a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_observation_test(None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cab3473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_observation_test(state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c1da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # To transform the image in the Processor\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Convolutional Backbone Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Keras-RL\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f8aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc261eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions                            mmmmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7180fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42785eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    def process_observation(self,observation):\n",
    "        if type(observation) == type(None):\n",
    "            whiteFrame= 255 * np.ones((640,480,3), np.uint8)\n",
    "            observation=whiteFrame\n",
    "        # First convert the numpy array to a PIL Image\n",
    "        img = Image.fromarray(observation)\n",
    "        # Then resize the image\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        # And convert it to grayscale  (The L stands for luminance)\n",
    "        #img = img.convert(\"L\")\n",
    "        # Convert the image back to a numpy array and finally return the image\n",
    "        img = np.array(img)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "\n",
    "        # We divide the observations by 255 to compress it into the intervall [0, 1].\n",
    "        # This supports the training of the network\n",
    "        # We perform this operation here to save memory.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186761e4",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "**NOTE: Depending on your custom environment, this model will vary greatly, try reading papers that are solving similar problems to your own!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "096ac5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (IMG_SHAPE[0], IMG_SHAPE[1],3)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35f9ad2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 84, 3, 84] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34964\\1235135807.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'he_normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'he_normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             raise ValueError(\n\u001b[1;32m--> 348\u001b[1;33m                 \u001b[1;34mf\"One of the dimensions in the output is <= 0 \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[1;34mf\"due to downsampling in {self.name}. Consider \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;34mf\"increasing the input size. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 84, 3, 84] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35dbd1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_37 (Conv2D)          (None, 82, 82, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 80, 80, 32)        18464     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 204800)            0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                4096020   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,116,276\n",
      "Trainable params: 4,116,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))  # (28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_actions, activation='softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e5bac",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "071a2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bfe38446",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e8090bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "15e33f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "              train_interval=4, delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1581c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eb0c7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = 'test_dqn_worker_weights.h5f'\n",
    "checkpoint_weights_filename = 'test_dqn_' + \"worker\" + '_weights_{step}.h5f'\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c25f0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500000 steps ...\n",
      "worker_pos 0 0\n",
      "The action is : (0, 0)\n",
      "reward, done, info 0 True {}\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_37_input to have 4 dimensions, but got array with shape (1, 20, 84, 84, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2360\\1447580431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# After training is done, we save the final weights one more time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# This is were all of the work happens. We first perceive and compute the action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;31m# (forward step) and then use the reward to improve (backward step).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Select an action.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[1;31m# Validate and standardize user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         inputs, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1305\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_tensors_from_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m         )\n\u001b[0;32m   1307\u001b[0m         \u001b[1;31m# If `self._distribution_strategy` is True, then we are in a replica\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2655\u001b[0m             \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m         )\n\u001b[0;32m   2659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2693\u001b[0m                 \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m                 \u001b[0mexception_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m             )\n\u001b[0;32m   2697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    720\u001b[0m                         \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m                         \u001b[1;33m+\u001b[0m \u001b[1;34m\" dimensions, but got array \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m                         \u001b[1;34m\"with shape \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m                     )\n\u001b[0;32m    724\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_37_input to have 4 dimensions, but got array with shape (1, 20, 84, 84, 3)"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=1500000, callbacks=[checkpoint_callback], log_interval=100000, visualize=False)\n",
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78381eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Gym)",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
